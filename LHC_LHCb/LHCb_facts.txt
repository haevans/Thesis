Here are some very interesting facts about LHCb collated in order of the parts of the detector.

The sources are
Will Barter's Thesis - his reference 80 is used a lot
Ed Greening's thesis
Marco's thesis
Alessio
https://lhcb-public.web.cern.ch/lhcb-public/en/detector/Trackers2-en.html
http://mipt.jinr.ru/xdocs/blum.pdf
https://en.wikipedia.org/wiki/Wire_chamber

Notes about actual writing
------------------------------------------------------------------------------
> Alessio does a nice overview of what the detector aims to do and also what happens to particles in a collision - ie b hadrons produced at the collision points, move through the velo and decay, move through rest of the detectors then the trigger gets rid on most events.
> Have a consistent set of facts accross all detector parts or at least the most similar parts ie the tracker TT, T1-3
> Should revise the basic principles of how each part of the detector works - the basic principles



LHCb in general
##################################################################
Marco and Will put the references in the chapter intorduction, this is nice.
> Single arm forward spectrometer designed to study particles containing b quarks
> studies CP violating and rare decays mostly within particles containing b quarks
> Production of b quarks is donimated at the LHC by gluon-gluon splitting, quark-antiquark annihilation and gluon fusion (Will's thesis has a reference) therefore b quarks are boosteed along the beam pipe, hence the design of LHCb.
> B quarks are light compared to the energy in the parton collision, therefore they are higly boosted and end up near the beam pipe. 
> There are some plots of the angular distribution
> LHCb measures from 10 to 300mrad in horizontal plane and from 10 to 250 mrad in the vertical plane, which corresponds to 2.0 to 4.5 pseudorapidity. Horizontal > vertical because of the magent bending particle trajectories.
> pseudo rapitidy is eta = -log(tan(theta/2)) where theta is the angle between the particle and the beam axis.
> Coordinates are on the LHCb picture, z is the beam axis, y the vertical and x the horizontal. Beams collide at the origin. The z axis is the ideal proton orbit around the LHC.
> detector is 10m in length (?)
> Alessio does a nice overview of what the detector aims to do and also what happens to particles in a collision - ie b hadrons produced at the collision points, move through the velo and decay, move through rest of the detectors then the trigger gets rid on most events.
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


Tracking 
##################################################################
> velo, magnet, TT , T1-3
> goods tracking needed to give good momentum resolution which will lead to good mass resolution which can be used to get rid of signal and background events
> reconstruct electically charged particles as they travel throught the detector
> momentum and therefore quanties related to the moment can be measured from the tracks because there is a magnet
> Momentum is also important to interpret the RICH
> Alessio's thesis has a nice figure of how the different tracking stations are used together
> Differences between types of tracks are:
  - Velo tracks leave tracks only in the velo!
  - T tracks are only in the T1-3 stations and are usually produces by secondary interactions of particles with the detector material
  - Upstream tracksa are in the velo and TT only
  - Downstream tracks are in teh TT and T1-3 stations
  - Long tracks are in the velo, TT and T1-3 stations
> Alessio has information about the track reconstruction algorithms
> Mometum resolution is directly effected by multiple scattering in the detectors therefore tracking detectors are designed to minismise the material in the detector acceptance
> Marco also talks about the track reconstruction
> "The study of CP violation and rare decays in the heavy flavour sector requires the accurate measurement of production and decay vertices and track impact parameters, both for avour tagging and for background rejection. The most stringent demands on the vertex reconstruction arise from the decay time resolution requirements to resolve the fast flavour oscillations induced by B0 s{B0s mixing."  Performance paper,


VELO - vertex locator
##################################################################
> This is next to the beam pipe 
> designed to track charged particles and to reconstruct decay verticies, including secondary verticies of B mesons
> identifies the displacement of the SV from the PV - charateristic of B hadron decays.
> velo also computes the luminoscity using van de meer scans
> find coordinates of tracks next to the interaction point
> B hadrons travel about 1cm before decaying because they have a long lifetime ~1.5ps for the Bs. If we have good vertex resolution this property of B mesons can be used to get rid of backgroud events
> the velo is used to locate tracks/verticies, in the velo the magnet's field is very low, straight track trajectories made in the velo are used as seeds in track resonstruction, used as a pileup detector.
> The VELO can make the best vertex locations and impact parameters if it is very close to the beam.

> There are 21 statins in the VELO on each side
> each half of the velo is the same as the other but they are displaced by 150mm in the z direction which allows them to overlap
> 2 additions stations up stream of the interaction point that are used in the pile-up veto system to remove events that contain too many proton interactions
> the pile up part is 2 segments/things that detect the number of primary interactions and also the track multiplicity in one bunch crossing for LHCb we want about 1 interaction per event (I think)
> The VELO is silicon micro-strip detectors and they alternate as to whether they cover radial or azimuthal coordinates. Each half of the VELO is made to overlap so stop edge effects
> Each half of the VELO is in an aluminum box, since the velo site in the LHC vacuum the box protects the vacuum from potential gas leaks from the modules and also keeps the velo electronics free of the RF EM fields generated by the beam. These are called RF boxed. Where the boxes meet they are corrugated to let them come together well, this part is called the RF foil and is part of the material budget of the VELO
> material budget comes to 17.5% or a radiation length.
> velo stips are 100 micro meters in width
> The Velo can retract, stable beams 8mm from beam during injection 3cm. The VELO can make the best vertex locations and impact parameters if it is very close to the beam.
> There are R-sensors and phi-sensors that alternate. The position on the sensors and z-distance of the sensor shows where the particle went
> R sensors have concentric rings from the ceneter but the distance between strips gradually gets larger (pitch) from the center outwards (Nice picture in Ed's thesis)
> R sensor strips are split into 4 45degree regions so have low capacitance and occupancy, the closest is 8.2mm from the nominal beam axis.
> phi sensor have an inner and outer region where the inner strips are shorts and the 2 sections are skewed wrt each other (Nice picture in Ed's thesis)
> phi sensor split in two due to occupancny and resolution reasons
> skewed phi strips help with pattern recognition
> veto z set up so it covers full lhcb acceptance and also each track goes through at least 3 sensors
>Î©. It can determine inpact parameters to a resolution of 13 microns for high momentum tracks
 the velo forms part of the tracking system
> best resolution is 4 micrometers which allows a lifetime measurement of 50 fs (there's a reference in Ed's thesis)
> In a typical event at LHCb 30-35 tracks per interaction vertex are reconstructed which leads to a PV resolution of 12 micro meters in the transverse plan and 65 along the beam axis.


Also should probably revise how a silicon strip detector works!

Prephaps something like
- What is the velo, what does it do and what are the physics motivations for this. (Primary goal is verticies but also does pile up and seeds reconstruction - maybe not important?)
- How does the velo acheive it's goals, how is it made, it can move (why?)
- How does the Velo perform

Magnet
##################################################################
> Main component of the field is in the y axis therefore the particles are bent horizontally
> Radius on curvature of a path of a charged particle is determined/comes from the momentum that a particle has
> Magnetic field covers the whole LHCb acceptance
> polarity is switched because many lhcb measurement are of asymetries because systematic effects are removed by switching the polarity and taking measurements from the mean of data with each polarity
> peak strength is 1.1T and intergrated field is ~4Tm for 10m tracks.
> field is neigliable in the RICH and peaks between the TT and T1 station,
> Hall probes were used to mapp the magnetic field - what are these?
> the agreement btwn measured and calculated field is better than 1% - see Will's ref 80
> Would be nice to have a picture of the field overlaid on the detector - Marco has this
> Warm dipole magnet
> magents strength allows momentum resolution of delta p / p ~0.4%
> polarity is inverted to study left-right asymmetries dectection effects and evaluate systematics for CP-vioation related analyses.
> The design of the magnet with an integrated magnetic field of 4 Tm for tracks of 10 m length had to accommodate the contrasting needs for a field level inside the RICHs envelope less than 2 mT and a field as high as possible in the regions be- tween the vertex locator, and the Trigger Tracker tracking station- LHCb detector at the LHC(it has potentially used references in)
- to get the required momentum resolutions for charged particles the magnetic field in- tegral   Bdl must be measured with a relative precision of a few times 10â4 and the position of the B-field peak with a precision of a few millimetres
- want to have no magnetic field in the RICH.


TT - Tracker turicensis
##################################################################
> silicon trackers with a pitch (distance between strips) 0f 200 microns. As in I think the angle between 1st and 2nd layer is 5 degrees if the 1st layer is vertical and the second is not quite vertical
> There are 4 layers and the middle 2 layers are rotated +/- 5 degrees wrt the vertical
> designed to detect low momentum particles that are swept out of the detector by the magent. So I guess covers at least the full LHCb acceptance. Combining Velo and TT tracks gives momentum accuracy of ~20%
> 150cm wide and 130cm high - active area of 8.4cm^2
> 4% of a radiation length
> within the fringe of the magnetic field
> higher momemtum tracks not bent out of the acceptance are used in the full tracking system for the momentum measurement
- The TT is a 150cm wide and 130cm high planar tracking station that is located up- stream of the LHCb dipole magnet and covers the full acceptance of the experiment.
- active area of 8.4m^2
- single hit resolution was needed to be about 50 micro meters, then the momentum resolution is dominated by multiple scatters over the full range of possible particle momenta. Read out strip pitches of about 200 micrometers achieves this.
The TT is kept at 5 degrees C to limit radiation damage
To aid track reconstruction algorithms, the four detection layers are arranged in two pairs, (x,u) and (v,x), that are separated by approximately 27 cm along the LHC beam axis.

T1-3 - Tracking stations
##################################################################
- IT active ares is 4.0m2
- The IT covers a 120 cm wide and 40 cm high cross shaped region in the centre of the three tracking stations downstream of the magnet. 
> These three stations are split into 2
> inner part (IT) of the stations are the same as the TT in design but smaller covering 120 by 40cm cross shaped region around the beam pipe with an active area of 4m^2 and a radiation length of 3.5%
> The IT covers 2% of the detector acceptance but 20% of tracks go through it so needs good resolution
> OT is a drift time detector
> Outer tacker is an array of gas tight Kapton straw tubes each with a diameter of 4.9mm, 70% argon and 30% CO2 fills them which gives a fast drift time of below 50ns and a resolution bettern than 200 microns
> outside of each tube acts as a cathode and there's a wire in the middle as the anode, the gas is ionised. A potential difference accross the tube makes an electron avalanche when a changed particles goes through.
> The OT has 4 layers like the TT and IT with the +/- 5 degrees rotation
> OT occupancy < 10% and the active area of 5971x4850 mm^2
> A picture would make clear the arrangement of the IT and OT in a station.
> silicon technology is expensive but offers high spacial resolution it is therefore only used in the inner part of the tracking stations
> IT dimensions chosen to keep IT occupancy < 10%
> "straw tubes are arranged in two staggered mono-layers "
> "An inner layer of carbon-doped Kapton (Kapton XC) acts as a cathode for the collection of the positive ions. The outer layer, made of a polyimide-aluminium laminate, provides shielding and together with the anode wire forms a transmission line for the effective transport of the high-frequency signals."
> Largest OT station overs 600 cm x 490 cm.
> OT has low track density but the IT has a high track density
> LHCb website and Alessio's thesis have a nice diagram showing the relative size differences between the TT and T1-3
> Mometum resolution is directly effected by multiple scattering in the detectors therefore tracking detectors are designed to minismise the material in the detector acceptance
>The OT tubes are 2-ish deep in each layer of the tracker so that they slot between each other and give maximum coverage/don't miss anything - arranged in 2 layers
> The +/- 5 degrees helps to improve the track reconstruction algorithms
The OT - do the tubes coved the whole vertical height of the detector? So you only know the x,z position of the particle? Alison said that is you know the time you can work out the vertical position - so prehaps I need to understand straw tubes.
>"If one also precisely measures the timing of the current pulses of the wires and takes into account that the ions need some time to drift to the nearest wire, one can infer the distance at which the particle passed the wire. This greatly increases the accuracy of the path reconstruction and is known as a drift chamber."
> "The outer parts of the tracking stations T1{T3 are equipped with a straw-tube detector (OT) [31]. Charged particles traversing the straw-tubes will ionise the gas along their trajectory. The drift-times of the ionisation electrons to the wire located at the centre of the straw are measured with respect to the beam crossing signal. The distribution of the recorded drift-time, which is proportional to the distance of the particle trajectory to the wire, is shown in Figure 9 (right)." Performace paper.

Why are the tracking +/-5 degrees?
Would be nice to explain how much larger the OT is compared to the IT and the TT in easy to read and understand terms. There's a picture to illustrate this.

How does the tracking work and preform?
#######################################
How does it work? - Performance paper tells me all
> tracks are defined depending on which tracking station they are detected in
>Velo tracks only have tracks in the VELO and are used to reconstruct PV
> T tracks cross the tracking statiosn T1-3 are are cause by particles being created from interactions from the detector, important for pattern recognition in the RICH 2
>> Up stream tracks leave stuff in teh velo and the TT, so are upstream of the magnets, typcially low momentum particles that are swept out of the detector acceptance by the magnetic field. Poor mometum resolution but can be used to undersand backgrounds in the RICH and help with flavour tagging of B hadrons
> Down stream tracks leave stuff in the TT and T1-3  the decay products of long lived particles
> Long tracks are in the whole detector and have the most previse resolutions, these are the most important for b-hadron decays
> Tracking algorithms take as seeds/starting points tracks in the VELO or the TT and then add information from the other detectors into the reconstruction.
> Once the tracks have been reconstructed they enable parameters linked to the tracks to be reconstructed, once a vertex position has been fitted for the the vertex chi2 can be found. Parameters such as the fligh distance and the flight distanace chi2 measure how far the particle moved before decaying. There is also the impact parameter which is wrt the interaction vertex, it is the distance of closest approach between the tracks and the PV (useful for b hadrons live a while)
> tracks in the VELO and T1-3 are used a seed to help find tracks in other parts of the detector, by searching in windows of the other detectors. Once the segments have all been found a Kalam fiter algorithm is used for fit the possible trajectories and this takes account of multiple scattering an dengery loss in the detector.
> fitter gives some tracks that are clones, these are removed bu an algorithm and the one with the most hits wins.
> if two or more tracks have many hits in common, the one with the most hits is kept
> fake tracks occur as well this is generally when the VELO and the T stations are incorrectly associtaed, the amount this happens depends on the multiplicty of the event and can be from 6.5% to 20%. Cuts are applied on a neural network to remove these.
> Kalam fitter gives a chi2/ndof for the track. LHCb makes requirements on these for each year to ensure that only good tracks are used. 
> tracking performace seems to be a diferent concept to the preformance of each detector. 
> Overall track momentum resolution is ...
> efficiency to correctly reconstruct tracks is ...
> IP resolution - from the VELO, varies with mometum, transverse momentun, it's ~35 mum for a particle with PT of 1GeV/c
> Vertex resolutions- this comes from the VELO, 10-25 mum transverse to the beam and 50-100 mum parallel to the beam, but it depends on the number of tracks in the event. There are plots in the performance papaer and VELO performance paper that ilustrate this. - needed for good decay time res, helps to identift types of B hadron and to remove background.
> decay time resolutions again from the VELO, this is super important to Bs ocisllating system. 50ns typlically, this was evaluated in Run 1.
> TT and IT have resolution of 50 mum in Run 1
> OT has fridt time of 35 ns and track resolution of ~200 mum for a particle with P > 10GeV, then mutilple scattering isn't what limits the resolution but the detector itself.
> Track efficiency is evalutated for long tracks since they have the best resolution and are also most important for physics analyses. Efficiencies vary with p, eta, nTracks and NPVs and they were computed with JPsi2MuMu tag and probe method (I don't understand how that works), the momentum resolution is also computed but this depends on the mometum of the final state particles(there is a nice plot) and therefore the mass resolution depends on the particle properties as well and it has been measured for different resonances and the Z. 
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

PID
##################################################################
> Designed to distinguish electrons, muons, protons, kaons and charged pions and also photons from neutral pions
> These are the daughter particles which are mostly what we detect, so we need to know what they are in order to find out what type of B meson they came from and also to distunguish events with similar kiniematics and topology
> Marco explains how the PID all works togerhter to get the DLL PID information


RICH
##################################################################
> Two RICH stations, one after the VELO and the other after the tracking stations, they cover complementary momentum and angular regions
> Ring imaging cherenkov detectors
> when charged particles go through a dielectriv medium they polarise it locally, if the particle speed it greater than the speed of light photons coherently interfer creating a wavefront at an angle theta_c wrt the particle direction (Maroc has a reference here) this angle is related to the particle velocity as cos(theta_c_) = 1/n.beta, where beta = v/c. If the speed is < c the photons deconstructively interefer therefore making no wavefront.
> Measuring the angle tells us how fast the particle is moving. This information combined with the mometum from the tracking stations tells us what the particle is - right?
>In the RICH light produced in the dewtector moves through the radiator and is refected off a spherical mirros on to a detector that is sensitive to the position. Hybrid Photon Detectors are used, but the magnet's field can degrade these so the RICH is protected/shielded so this does not happen.
> Rich 1 has a silicon areogel senstivit to up 10GeV and C4F10 sensitive to 10-60 GeV. All the mirros and detection stuff are locatioed outside the LHCb acceptance
> THe Rich 2 is sensitive to 15-100 GeV and is made of CF4. It covers +/- 120 mrad in the horizontal and +/- 100 mrad in the vertial so only where you expect to get high energy particles.
> The radius of the ring gives a measure of theta_c and therefore the velocity. 
> âThe RICH 1 detector is shielded from the magnetic field using iron plates which reduce the magnetic field in the HPD plane to a maximum value of 2.4 mT.â Will 
> It is the HPDs that need to be shielded.
> RICH detector give a ring of light, this light is related to the speed of the particle, therefore with the momentum from the tracking detectors the mass and therefore the identity of the particles can be determined. 
>  e, Î¼, â¡, K and p+ identification in the rich, They have to be charge particles.

Calorimeters
##################################################################
> these are behind the RICH 2 and consist of the preshower (SPD/PS), electromagnetic calorimeter (ECAL) and the hadronic calorimeter (HCAL)
> Calorimeters provide information to the trigger are hadron, electron and photn transverse momentum
> These measure the position and energy of hadrons, electron and photons.
> The SPD distinguished between neutral and charged particles, it is the Scintillator Pad Detector, it seperates photons and electrons which would have similar profiles in the ECAL
> The preshower(PS) is a thin layer of lead then scintillators like the SPD. It makes the most of the different interaction lengths of the electron and charged pion. Electrons will produce showers in the lead but the pions will not. This information is used the the trigger hlt1. 1% of pions will interact with the lead converter. This is necessary in case pions begin to shower in the ECAL.
> The ECAL is for electromagnetic showers and is used in the L0, it wants all the shower to develop in the ECAL for the best E_T resolution.
> ECAL has energy resolution os deltaE/E = 9%/sqrt(E)(+)0.8% where E is in GeV - this requires information from the PS
> HCAL energy resolution deltaE/E = 69%/sqrt(E)(+)9%
> functions of the Calo; L0 trigger from transverse energy of hadrons, electrons and photons, improved PID of electrons, photons and hadrons as well as energy and position. Reconstruction on pi0 and prompt photons needed for flavour tagging and study of B meson decays.
> PS does charged pions and electrons, SPD pi0. itâs scintillator lead scintillator
> all the calorimeters follow the same principle, scintillation light is transmitted to a PMT by wavelength shifting fibres.  When a particle looses energy via ionisation or excitation of atoms in a material it is travelling through, sometimes depending on the material this energy reemerges as visible or UV light which can then be measured by a PMT.
> A calorimeter detects energy of a particle by absorbing it, absorbers make showers of secondary particles and so on whilst scintillators or MWPCs detect the energy as light. I suppose the amount of ionisation and excitation depends on the energy of the incident particles.
> ECAL, scintillator/lead, same for the HCAL - sampling calorimeters
> EM calorimeters are when particles (electrons, positrons and photons) interact electromagnetically, through ionisation, bremstralung or pair production, depending on their energy.
> Hadronic calorimeters particles interact via the song force. 
> SPD is first, before an absorber so that electrons will make light in it but photons will not. Then there is a lead absorber before the PS, the PS is used to separate pion and election showers. 
> Why do pions interact with the ECAL?
> ECAL is designed to capture the whole shower where as the HCAL is not. 

Muon detectors
##################################################################
> 5 muon stations, one after RICH 2 the rest at the end after the HCAL
> high pt muons are used in the trigger because they will have come from interesting B mesons.
> muons have a high matter penetrating power compared to electrons, hadrons ets, this is expolited in the muon station positions and their makeups, this is because they do no interact via the strong force and they have a large mass so that energy loss through bremstralung is low
> the muons stations are outside the magnetic field, therefore track reconstruction is fast.
> They cover the full LHCb angular acceptance
> The granulartity reduces due to multiple scarttering that increase in likelihood with distance from the beam pipe
> There are ison absorbers of ~80cm between each muon station to remove particles that are not muons. There is also an iron wall after the end of the last muon station to stop particles travelling downstream into the detector.
> The stations used multiwire proporinal chamebers on the outer parts but the inner sections use gas electron multipler foils because the flunence is high in the inner most region and MWPCs won't get the needed effieicny.
> MWPC uses Ar, CO2 and CF4 at 40%, 55% and 5%. There is a pitch of 2mm. I think there is a high detection efficinecy because therer are 4 sentivive gas layers in each layer and only one layer needs to rehister a signal.
> GEM thin Kapton foil between copper plated 140 micro meter pitch A very strong volage is applied accross the copper plates.
> A muon is identified if hits in the muon station can be matched to what is seen in the tracking stations.
> âThe muon system provides fast information for the high-pT muon trigger at the earliest level (Level-0) and muon identification for the high-level trigger (HLT) and offline analysis.â
> muons are present in the final states of many b hadron decays
>âis composed of five stations (M1-M5) of rect- angular shape, placed along the beam axisâ
> âThe minimum momentum of a muon to cross the five stations is approximately 6 GeV/c since the total absorber thickness, including the calorime- ters, is approximately 20 interaction lengths.â
>â Station M1 is placed in front of the calorimeters and is used to improve the pT measurement in the trigger.â
> âStations M1âM3 have a high spatial resolution along the x coordinate (bending plane). They are used to define the track direction and to calculate the pT of the candidate muon with a resolution of 20%. Stations M4 and M5 have a limited spatial resolution, their main purpose being the identification of penetrating particles.â
> decay including muons are topologically similar to those including hadrons i.e. Bsmumu, B2pipi, B2pik! Therefore the muons allow good identification of penetrating muons with a low hadron mis ID probability
> Size of the muons stations increases with distance from the interaction point just like the OT stations
> the muon stations effectively cover the full LHCb angular acceptance
> âThe muon system covers the angular range 20-306 mrad in the horizontal plane, and 16-258 mrad in the vertical plane. This is su cient to capture about 20% of muons from semileptonic B decays [80].â
> the absorbers are made of iron
>âThe muon stations use two diâµerent technologies; multi-wire proportional chambers (MWPCs) are used for all regions except the inner region of M1. In this region the expected particle rate would exceed safety limits for ageing, so triple-GEM (gas electron multiplier) technology is used instead [80].â
> Quotes are from Willâs thesis or from the âLHCb at the LHCâ paper.


PID reconstruction
############################################################
https://indico.cern.ch/event/226062/contributions/475644/attachments/371741/517276/ANNPIDRetuning-Reco14-06052013.pdf

RICH
---
Olli -
"The RICH reconstruction algorithms perform a global likelihood fit, which considers all
possible mass hypotheses for reconstructed tracks that pass through the RICH detectors.
In Run 1 and during data-taking in 2015 six hypotheses were considered for each track:
electron, muon, pion, kaon, proton and âbelow Cherenkov thresholdâ.  An illustration of
the kaon-pion separation performance in Run 1 is given in Fig. 3.11. Starting in 2016 the
deuteron hypothesis will also be included, allowing several new analyses to be carried out.
...
 In the offline reconstruction both
binary (âIsMuonâ) and likelihood-ratio variables are calculated. These are based on finding
hits within a field of interest (FOI) in enough muon stations, where the required number of
muon stations and FOI size are dependent on momentum, and considering the distribution
of hits around the extrapolated track position.
Information from the RICH, calorimeter and muon systems is combined to produce, for
each charged particle track, a likelihood value for each mass hypothesis. Differences in the
logarithms of these combined likelihoods (DLLs) are used extensively in event selections to
distinguish different types of particle."



 "The PID information obtained separately from the muon, RICH, and calorimeter systems is combined to provide a single set of more powerful variables. Two different approaches are used. In the first method (DLL variables) the likelihood information produced by each sub-system is simply added linearly, to form a set of combined likelihoods. These variables give a measure of how likely the mass hypothesis under consideration is, for any given track, relative to the pion hypothesis. A second approach (ProbNN variables) has been subsequently developed to improve upon the simple log likelihood variables both by taking into account correlations between the detector systems and also by including additional information. This is carried out using multivariate techniques, combining PID information from each sub-system into a single probability value for each particle hypothesis.

Detailed information about the ProbNN approach can be found in this presentation by Chris, slide 10; information about the Run 2 version of the ProbNN variables can be found in this presentaion by Chris (slide 11)Some comparative study of DLL versus ProbNN variable performance (Run 1) can be found here (A. Pearce, PPTS of 8 Jul 2013) and here (A. Hicheur, PID workshop, Jan 2014)

ProbNN variables use information from the tracking and the 3 PID systems, CALO RICH and MUON. The variables used as input for the ProbNN can be found here, actually sued at runtime to list what variables are used (looking at a specific file: the first 5 lines are other settings, the inputs start on the 6th; lines with a # at the start are commented out, so not used). The names in these files can then be match to actually know how data are extracted by looking at this file, which shows the mapping between the name and a helper class, and then to this which shows exactly what each helper does.

The training of ProbNN variables is done using MC inclusive B events. Actual performance depends on the tuning (blending of MC samples) used. A large collection of information on the various tunes can be found digging in this folder. For general purposes MCTuneV2 and MCTuneV3 tunings are available, that have different performance (ID and/or misID) and can be used simultaneously, the choice depending on the specific analysis. The main difference between MC12TuneV3 and MC12TuneV2 is that ghosts have been removed from the training samples (explicitly the ghost have been removed from the backgrounds of all the networks excluding the ghost one). This leads to an improvement in the performance for electrons (have a look to slides 18-23 here for a summary of electron ID performance with the two tunings) while for the other particles it is not that simple to say whether MCTuneV2 or MCTuneV3 is best.

To see which tune performs better in a specific analysis it is useful that the MCTuneV2 and MCTuneV3 might coexist. Users can directly compare themselves the two tunings by means of the new TupleTool TupleToolANNPID. This tool can be configured with a list of tunes, and will add each (with the tune in the variable name) to each stable particle you ask it to. The values are computed on the fly, rather than relying on the values saved in the ProtoParticles, and thus is able to save more than one tuning at the same time, which previously was not possible. " PID Global Twiki https://twiki.cern.ch/twiki/bin/view/LHCb/GlobalParticleID

"Tip on DLL values (i.e. Why there is a peak at PIDx == 0?)

The reason for the peak is any DLL is the difference between two species, one normally being pion. So PIDk is actually DLL(K-pi).

If the expected signature of the RICHes is below Cherenckov threshold for both species, no Cherenkov light is emitted and the signature for both is the same. In short RICH cannot tell them apart and the DLL(K-pi) == 0. precisely. Note that in Run2 the spike at 0 will be much larger than it was in Run1, due to the fact Aerogel has been removed and thus the effective momentum thresholds for a number of tracks will be increased (defined by C4C10 instead of Aerogel).

Practically, placing a cut (< or >) at precisely 0 is a bad idea because this means to cut on a delta function. The correct approach is to demand at least one of the two mass hypotheses in the DLL difference is above threshold as this is enough to make sure the signatures in the RICHes will be different, and thus the DLL is not 0. The "above threshold" request can be made either via the RichPID data objects (which have methods to do this) or via a direct momentum cut "

"Photons    come    in    two    types,    nonconverted    &    converted    (i.einteracted    with    an    upstream    detector    to    make    a    e+e-Â­â    pair)    "
Reasons    for    misâID of Muons;
- Spurious    hits    in    muon    system    
- Real    muon    in    event    with    similar    trajectory    
- As    P    increases    the    windows    for    search    decrease    and    more    hits    are    required,    hence    the    drop    in    misâid    rates.    
- Decays    in    flight    for    kaons    and    pions    hence    larger    misâid    rates    than    for    protons    

- DLL are combined log likelohood, they combine the likelihood fits from the RICH, Calorimeters and the Muon stations, everything is done relative to a particle being a pion
_ DLL combined tracking with PID information for the whole event, it is the difference in log likelihoods between a track having 2 different mass hypotheses
- Each sub-system provides log-likelihood information (differences) on the particle species it is able to distinguish. 
- DLL give a measure of how likely the mass hypothesis under consideration is, for any given track, relative to the pion hypothesis.
- ProbNN  variables    are  neural networks that are trained    on    MC    using:    RICH,    CALO,    MUON    PID, the RICH    Radiation Threshold    Info    and VELO and tracking information
- ProbNN training done using MC inclusive B events.
- ProbNN and DLL have different performances with decay kinematics eg track mometum. The best depends on the situation.    
 - ProbNN uses both by taking into account correlations between the detector systems and also by including additional information
- Also for muons there is a binary selection, that requires hits in a certain number of muon stations depending on the muon energy, within a cetain field of interest which is extraploated from the tracking stations to identify a muon. Fir 3<p<6 DeV nust have hits in M2-3, 6<p<10 hits in M2-3 and either 4 or 5, p > 10 hits in M2-5.

- main muon mis ID comes from decays in flight of kaons or pions, ie the particles decay making muons and get reconstructed as muons and not kaons or pions.

Trigger
#################################################################

> The collision rate at the LHC is too high to be read out by the detector, therefore a trigger is needed that selects events that could be interesting for physics reasons and only these are stored offline
>50ns bunch crossing at LHCb in Run 1 - 2015 50 and 25ns 
>In run I the trigger reduced the rate of events to be saved for physics analysis to 2 - 5kHz
> The difference between online and offline resonstruction in Run 1 are the simpli ed reconstruction, possible misalignments and reduced resolution, as compared to the oine reconstruction.  
> A "trigger line" is composed of a sequence of reconstruction algorithms and selections.  The trigger line returns an accept or reject decision.  An event will be accepted by L0, HLT1 or HLT2 if it is accepted by at least one of its trigger lines at the relevant stage
> only about 15% of these events will include at least one B meson with all its decay products contained in the spectrometer acceptance. Furthermore the branching ratios of interesting B meson decays used to study for instance CP violation are typically less than 10-3 . The offline analysis uses event selections based on the masses of the B mesons, their lifetimes and other stringent cuts to enhance the signal over background. For the best overall performance the trigger was therefore optimised to achieve the highest efficiency for the events selected in the offline analysis,  while rejecting uninteresting background events as strongly as possible

> The purpose of the L0 trigger is to reduce the LHC beam crossing rate of 40 MHz to the rate of 1 MHz with which the entire detector can be read out. Due to their large mass, B mesons decays often produce particles with large transverse momentum (pT) and energy (ET) respectively. 



Hardware trigger
> LHC bunch crossing frequency can be up to 40 MHz
> L0 must reduce it to 1 MHz which is the rate that the full detector can be read out.
> latency of the L0 us 4\mu seconds and it is built from custom designed software
> There are 3 inputs to the L0; the VELO pileup veto system which is used mainly for luninoscity measurements rather than physics analyses, it estimates the number of PVs in an event; the Calorimeters, these identify electron, hadrons and photons for the triggers by looking at energy deposited in different parts of the detector; the muons stations, fast reconstruction of muons is done and they have to have a minumum PT to be triggered.
> electron and hadron triggers - identifies highest ET photon and electron in the ECAL, highest ET hadrons in the HCAL and two highest PT hadrons in the muon stations. These candidates then have to pass PT thresholds and nSPD hits. SPD multiplicity/hits is the number of charged tracks passing through the SPD in an event is gives a measure of the occupancy of the event. Events with high occupancy take a longer time to reconstruct in the software triggers, inefficiency and CPU intensive. These candidates are removed to get optimal HLT performance.
> PT requirements change per year to make the most of the resources avaliable given the pp CoM energy
> There are also dedicated trigger lines to detect Central Exclusive production, very low occupancey is charteristic of these events ( Will has a reference).
> if an events passes any of the trigger lines then the entrie event is read out and recorded.
> The L0 trigger is divided into three triggers ; the L0-Calorimeter trigger, the L0-Muon trigger and the L0-PileUp trigger, the latter being used only for the determination of the luminosity 
> The L0Dimuon trigger adds a small number of events to the L0Muon trigger - there are some potentially useful plots in the preformance paper
> The L0 system is fully synchronous with the 40 MHz bunch crossing signal of the LHC.

Software Trigger
> For Run 1: The HLT is divided in two levels.  In the  rst level (HLT1), a partial event reconstruction is performed.  In the second level (HLT2), the complete event is reconstructed.  Where time allows, the HLT uses the same reconstruction algorithms as employed oine, with some simpli calculations that are needed to satisfy the time constraints. 
>Hlt1 seems to just use tracking and mometum for each L0 trigger
> aim of the HLT1 is to confirm the L0 trigger decisions but it uses more infomration from the detector.
> reduces 1MHz from the L0 to what can be processed offline whic was 3.5kHz in 2011 and 12.5kHz in 2015 due to increase in computing resources. Olli
> approximately 5kHz is saved (Run 1) - Simon
> HLT1 usese the VLOE and the tracking stations, output rate was 80 kHz in 2012 and 40 kHz in 2011
> there are many specific trigger lines, there are some that select a lot of B2MuMu events but these change each year! I don't want to go into them. Prehaps I can talk about them later in the analysis section?
> HLT2 preforms full event reconstruction for all events that pass at least one HLT1 line, provided that tracks pass a some minimum requirements on the p and pt. pt > 0.5 GeV and p > 5 GeV in 2011 and pt>0.3 GeV in 2012.
> HLT2 lines provide information for specific analyses, there are many. Some are specific to certain decays, others look for particluar types of particle and some are topological triggers (these use momentum and VELO info to select tracks that are higly displaced from the PV)
> Trigger decisions; TOS, triggered on signal, the tracks that make up the signal candidate were sufficient to trigger the event; TIS, triggered independant of signal, if the tracks and hits associated with the signal are removed then then event would still have passed the trigger. Dec, Decision, refers to whether a particular trigger line 'fired' or was passed by an event, TIS and TOS are included in this and so is something else I'm not sure about (not 100% sure of this one). This can be done for each line or globally. 
> run on a dedicated computer farm offline. 
> HLT1 must process an event in 12ms, so although it can access the full detector readout, full event reconstruction is too slow to be used in the HLT1 lines. 
> NB Will has a nice diagram that illustrate the levels in the trigger. 
> Should I include some trigger efficiencies? Or I can put these later in the Thesis?
> HLT1 and HLT2 lines vary for each year, particulary there are new or modified lines for Run 2 compared to Run 1. The thresholds for the L0 changed but not he lies thenselves. NB I should have mentioned Run 1 and Run2 before now, prehaps in the LHC section. 
>all events passing the HLT are stored on disk, there offline reconstruction is then done (Run 1) which is different to online reconstruction which is used in the trigger. I'm pretty sure for Run 2 that online reconstruction replaces offline reconstruction because of the Turbo stream.
> HLT1 rate is low enough to allow full event reconstruction
>  In all there were around 100 HLT2 selections in
the 2011 configuration, 200 in 2012 and around 450 during 2015 data-takin
> Olli has schemes for 2011, 2012 and 2015 triggers
> L0 events are deferred to disk where the HLT trigger is used
Run 1 and Run 2 and the HLT from Olli's thesis
> in Run 1 there were clear distinctions between the event reconstructions used the the HLT1, HLT2 and the offline reconstruction
> Between 2011 and 2012 the size of the Event Filter Farm was increase by a bit and a 'defferal' scheme was introduced.  "Averaged over a typical period of data collection, theLHC delivers stable beams around 30 % of the time, so, if theHLTwere to operate fully synchronously with collisions, the EFF would sit idle for the remaining 70 %. To optimise the use of EFF resources, around 20 % of the events accepted by the L0 trigger were saved to local hard drives of the EFF nodes in 2012. The HLT processed these events later, when the LHC was not providing stable beams." This effectively increased the CPU avalible to the HLT, and allowed down stream tracks (Olli has ref) to be resoncturced in the HLT2 which imporved the effucuency of selecting Ks and lambda^0
> Run 2 and HLT2 "The HLT underwent significant changes during LS1, the long LHC shutdown separating Run 1 and Run 2. Instead of deferring a fraction of the L0 trigger output, the entire output of HLT1 is saved to the EFF local disks in Run 2, as illustrated in Fig. 4.1c. This new mode of operation allows the detector to be aligned and calibrated [143] before HLT2 is executed, enabling HLT2 selections to make use of offline-quality reconstruction informa- tion, and ensuring optimal use is made of EFF resources. Improvements to the computing infrastructure permit more processing time to be allocated to each event in HLT2, and allow around twice as much data to be output by HLT2. The additional processing time is used to perform higher-quality reconstruction than the Run 1 HLT , including full reconstruc- tion of the RICH detectors and calorimeter systems, which were only used sparingly in the Run 1 HLT2 due to timing constraintsThe reconstruction performed in the Run 2 HLT2 is of sufficiently high quality that no offline reconstruction is necessary for some data (the Turbo stream, Sect. 4.2.4), and thismust only be performed once for the remaining data. In contrast, in Run 1 a second offline reprocessing was required after the detector alignment and calibration had been performed."
> In run 2 different HLT2 lines are saved to differnt places. 
Full
This is similar to Run 1, minimal information is saved from HLT2 and physics analysis depends on the offline reconstruction. It is typically used for signals that are not fully reconstructed in HLT2, such as b -hadron decays selected by the inclusive trigger, or for analyses that need to [re-]run dedicated event reconstructions, such as searches for very rare decays and modes with neutral particles. 
Turbo
Sufficient information is saved from HLT2 that no offline reconstruction is required prior to physics analysis [148]. This stream is suitable for analyses that are fully reconstructed in HLT2 and do need the full reconstructed event information. In principle the raw event information is discarded to save storage space, although in practice this information was retained during 2015 data-taking. 
TurboCalib
Information is saved from HLT2 as in the Turbo stream, but the raw event information is retained and the offline reconstruction is also performed. This consists exclusively of calibration selections for online monitoring and measurement of PID and tracking efficiencies. 
> The HLT is based on the same software as used throughout LHCb data processing and simula-tion 

Things I don't understand about the trigger - 
 - If alignment and calibration occured before HLT in Run 2 where did they occur in Run 1 and what is they purpose?
 - What is a 'flow chart' of data analuysis in LHCb, to go from a particle moving through the detector to a stripped data set?
 - prehaps I should change the order to that it's 1. 'flow chart', 2. Trigger, 3. Stripping

Event stripping
> each analysis has it's own stripping lines
> the full offline reconstruction in run using information for all sub detectors. Selection is applied to select specific decays and to reduce the amount of data making it to a size that is relevant to each analysis and so an analyst can use it. For example, B2MuMu only cares about muons so if an event doesn't contain a muon who cares? We use this information to remove background events so we end up with a data set that is enhances with signal events and is a sensible size. 



Software, MC and stuff like that.
#################################
(Harry)
-  Once data has passed the trigger it must be processed before it can be used in physics analyses.

GAUDI FRAMEWORK
- C++ framework used accross the experiment that ensures that changes are made smoothly and universally and all tools and algorithms are avaliable accross the experiment
- the conditions data base store information about the running conditions of the experiment which is something that changes throughout the experiment. It also allows simulated data to be produced. 
- framework implemets the software
- suited to the a distributed computing system, which is great because LHCb uses the world wide LHC computing grid. The GRID allows data to be stored all over the world and the analysis code it then sent to where the data is so that the data does not need to be transported to the analysts. The GRID is managed by DIRAC software and jobs are submitted via the GANGA project. 

SIMULTAION
- simulation software provides simulated events mirroring what happens in data. The Gauss application is used to do this, it uses Pythia with and LHCb specific configuration to model proton-proton collisions and the production of particles. The EvtGen application calculated the flight of these particles through the detector volume and their decays.
- Generated events are ususally forced to include a particular signal decay of interest
-Boole applicaition deals with the response of the detecotr to the simulated events, the model of the detector is based on GEANT4, it simulates the detector's digital output which can then be passed through the same trigger, reconstruction and analysis chain as real data
- Final state radiation if modelled by PHOTOS.
- a GEANT4 toolkit is used to describe the interaction of particles with the detector and its response.
- the same trigger software and offline reconstruction algorithms are used for simulated data as for real data, but also additional information about the generated particles is kept to be used when the data are analysed.

RECONSTRUCTION
- Burnel takes digitised readout of the detector, either from simulation or from data and produces data that is of physics interst, such are momentum, energy and PID measurements. It takes hits in the tracking stations and preforms fits to determine the trajectory and momentum of particles. Takes clusters of energy deposited by showers in the calorimeters to get particle energy, performed a combined reconstruction of the different PID detectors to produce the PID variables. 
- the output of Brunel is a full reconstructed dataset known as a "Data Storage Tape" (DST) or microDST file.
- DaVinci assigns particle hypothesis given information from BRUNEL, this enables it to compute particle masses of intermediate and parent particles. 
ANALYSIS
-DaVinci, takes track objects from Burnel and preforms fits to produce PVs and SVs and calculates a wide range of kinematic properties needed for anaylses, ie proper time, distance of flight. DaVinci also allows the implementation of the Stripping Proceedure which are series of particle selection sequences. The output of DaVinc is with a ROOT ntuple file that is used directly for measurements or a DST file with can be processed futher.
- ROOT enables easy visualisation for data in histograms, a ROOT tuple includes all information requested by the analyst.
- the RooFit package sits inside the ROOT framework and enables fit to the data to be performed. 
- "The stripping produces signal candidates using particles found in the offline reconstruction and applies additional selection requirements to improve signal purity."
- in some stripped files, only the signal candidate is save whilst others keep the fully reconstructed event
- the output of the trigger is too large to be stored and used by all the analysts therefore stripping lines are used. Aim is to keep as much of the signal as possible but reduce background events by applying loose selection cuts.
